From a conceptual point of view (and how we will implement concept engine) -- 
There are (only) three types of words:
- Perception (identifications)
- Pertained Perception (decorations/properties)
- Time-Varied Pertained Perception (process)
- The rest are purely logical
For example: Colorful refers pertained perception of specific objects, while hurt refer to perception, and eat refer to time-varied pertained perception; While if/or/of/and define logics, as mentioned below
Since all types above are ultimately perceptions, there is no fundamental conceptual difference between "apple" (an object) and "Louis ate half an apple and threw the rest away" (an event/action/process)
There is no such a thing as time, but only the order of things happening
Obviously, as how fine-grained one can perceive physical signals, the above "the order of things happening" can contain a multitude of layers (LOD) depending on how detailed a perception is, for example, "the world is getting better" is a general perception involving "world" and "getting better" and as such its meaning DOES NOT pertain to any specific object (the statement is only valid on its current LOD level), while "Louis ate half an apple and threw the rest away" involves a sequence of perceptions "Louis" "ate" "apple" "threw away" "the rest (of the apple)", thus this statement operates at a different LOD level. One can measure the LOD level (the higher the more detailed) of a statement by measuring the mentioned concepts in it (which roughly equals the number of words in it). For such, if we treat a whole book as one extremely long statement, its LOD level is clearly much more higher than a single statement less than 20 words.
As such, perception of language itself, as in Airi, has an upper boundary on how detailed it can operate on, this is called "abstraction" -- just like what we did for other physical perception engines of Airi. Airi operates on an LOD level that is high (conceptually speaking this should sound "low" per abstraction level but "high" in terms of amount of details, in which case a single symbol ideally refers to the highest abstraction level yet lowest LOD level) enough to encompass different communication needs.
There are four sources of such knowledge:
- Void (non-menaingful words, i.e. those that are not related to any perception at all, which to Airi effectively looks like 10110110(apple) or 10110011(apple))
- Reading from other informative source (in which case concepts are only virtual and not taken for granted), e.g. when reading a book, both void words and meaningful words are encountered and concepts collide with each other (either appear as non-intuitive because no known methods was known or non-associative because no known perceptions can  be related e.g. new words), those are precious learning experience that will be constantly keeping track of, and later at appropriate time through different means get dissoved (e.g. accept a void word as is and accept its virtual properties which doesn't refer to any specific physical perception e.g. non-observable symbols/objects/mathamtical objects which are defined only by  "abstract"(virtual) properties and operations; or associate it with later determined physical signals; By assocaite it blurrly with other solid perceptions)
- Designer specified granted as truth (which serves as the basis): implementationwise we will provide a set of "perceptable objects (both ID and process and properties)" which are essentially just list of words (since we don't need to associate such to actual physical perception signals in Core), but when loaded into Airi those concepts have implied physical perceptions related to them (i.e. providing a port to physical engines and physical signals); The implementation of this set of concepts will be the same as below, which are not designer specified/participated at design stage
- First hand experience with or without language reference (through physical perceptions): through contact, conversation, experience (e.g. through available physical engines, or in VGW), Airi associate different experiences (i.e. a multitude of different levels of perceptions) internally
Ultimately perceptions are about connection, the more connections a concept/word has, the more well defined it is, and thus more details it can be converyed into. For example at first {Apple}(Perception of apple object) and "Apple"(symbol of word) and "Eat" are isolated nodes in memory space, then gradually "Apple" is attributed to {Apple} along with "Color"{Color} (P/S pair) and "Size"{Size}(P/S pair) and "Weight"{Weight}(P/S pair) and "Food"(Logical attachment/constrct); "Eat" associated wiwth "Food"(Logical attachment/constrct) and {Eat}(A complicated physical process pending definition but simply reserved here). Notice the same symbol can be associated with multiple perceptions (both virtual and physical) -- as we have said, only perceptions are specific, and words doesn't need to be, e.g. "Apple" can refer to {An apple in the past expereince memory} or {A virtual apple created for this discussion}.
Concepts as mentioned above (core memory/knowledge) are seperate from experience (event memory/past), with later being only sequence of occuring perceptions (can be physical or lingual, with later being treated as a form of physical signal essentially), and are recorded in order inside a log/journal section of memory (and for such no connections are established there, just sequence of records).

There are several rules about language interpretation:
- Always operate on an object (real or virtual, but all are imaginary in perception/memory/mind)
- Logical constructs doesn't have perceptual meaning, but server as a means to program the mind
- Some words and phrases convery similar or the same meaning. We use whichever we used most (so this is a personal custom/habit/preference, rather than a conceptual difference)

Definitions:
- All words can contain properties and operable methods with targets (i.e. not just nouns has properties, and not just verbs has operable methods and targets)